# mso-workflow-optimizer / llm-as-a-judge
# Copy this file to `.env.local` (or `.env`) and fill in real values.
# Model catalog: `{mso-workflow-optimizer}/configs/llm-model-catalog.yaml`
# Quick selector: `python3 {mso-workflow-optimizer}/scripts/select_llm_model.py --provider openai`

# Provider selection: openai | anthropic | google
LLM_API_PROVIDER=openai

# Preferred common key (used first if set)
LLM_API_KEY=

# Provider fallback keys (used when LLM_API_KEY is empty)
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
GOOGLE_API_KEY=

# Optional endpoint/model overrides
LLM_API_BASE_URL=
# Choose LLM_MODEL from `{mso-workflow-optimizer}/configs/llm-model-catalog.yaml`
# openai:    gpt-5.2 | gpt-5.2-pro | gpt-5.2-mini | gpt-5-nano | gpt-4.1-nano | o4-mini
# anthropic: claude-sonnet-4-5 | claude-opus-4-6 | claude-haiku-4-5
# google:    gemini-2.5-pro | gemini-2.5-flash | gemini-2.5-flash-lite
LLM_MODEL=gpt-5.2
